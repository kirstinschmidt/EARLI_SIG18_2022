---
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    seal: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---

name: title
class: center, middle, hide_logo

```{r, eval=FALSE, echo = F}
dir.create("style_file")
```

```{r xaringen-themer, echo=F, warning=FALSE, message=FALSE}
#install.packages("xaringan")
#install.packages("xaringanthemer")
#library(xaringanthemer)
#style_mono_light(
#  base_color = "#001c05",
#  header_font_google = google_font("Times New Roman"),
#  text_font_google   = google_font("Times New Roman", "300", "300i"),
#  code_font_google   = google_font("Fira Mono")
#)

#colors = c(
#  red = "#f34213",
#  purple = "#3e2f5b",
#  orange = "#ff8811",
#  green = "#136f63"
#)

library(xaringanthemer)
library(xaringanExtra)
library(readxl)
library(tidyverse)
library(ggalt)
library(hrbrthemes)
library(reactable)
htmltools::tagList(rmarkdown::html_dependency_font_awesome()) 

extra_css <- list(
  ".cit"  = list("font-size" = "70%",
                 "color" = "#6AEE3E90"),
  ".em05" = list("font-size" ="0.5em"),
  ".em06" = list("font-size" ="0.6em"),
  ".em07" = list("font-size" ="0.7em"),
  ".em08" = list("font-size" ="0.8em"),
  ".em09" = list("font-size" ="0.9em"),
  ".em11" = list("font-size" ="1.1em"),
  ".em12" = list("font-size" ="1.2em"),
  ".em13" = list("font-size" ="1.3em"),
  ".em14" = list("font-size" ="1.4em"),
  ".em15" = list("font-size" ="1.5em"),
  ".bold" = list("font-weight" = "bold"),
  ".medium" = list("font-size" = "130%"),
  ".large" = list("font-size" = "160%"),
  ".vertmiddle" = list("vertical-align" ="middle"),
  ".lh15" = list("line-height" =  "1.5"),
  ".lh16" = list("line-height" =  "1.6"),
  ".lh18" = list("line-height" =  "1.8"),
  ".li" = list("line-height" =  "1.5",
               "font-size" = "160%",
               "font-weight" = "bold"),
  ".phgreen" = list("color" = "#50B32E"), 
  ".phgreenlight" = list("color" = "#8CD000"),
  ".lightgrey" = list("color" ="#b3b3b3"),
  ".my-footer" = list("background-color" = "#1a1917",
                      "position" = "absolute",
                      "bottom" = "0px",
                      "left" = "0px",
                      "height" = "20px",
                      "width" = "100%"),
  ".my-footer span" = list("font-size" = "10pt", 
                           "color" = "#F7F8FA",
                           "position" = "absolute",
                           "left" = "15px",
                           "bottom" = "2px"),
  ".remark-slide-number" = list("bottom" = "18px"),
  ".li" = list("line-height" =  "4"),
  ".scroll-box-18" = list("height" ="18em",
                           "overflow-y" = "scroll"),
  ".scroll-box-23" = list("height" ="23em",
                           "overflow-y" = "scroll"))

style_mono_accent_inverse(
  #text_color = "#ffffff",
  base_color           = "#8CD000",
  white_color = "#FFFFFF",
  black_color = "#272822",
  header_font_google   = google_font("Roboto", "700"),
  text_font_google     = google_font("Roboto", "500"),
  code_font_google     = google_font("Droid Mono"),
  extra_css = extra_css#,
  #inverse_background_color = "#000000"
  #inverse_text_color = "#ffffff",
  #link_color = "#6AEE3E"
)

use_logo(
  image_url = "https://live.staticflickr.com/65535/50974533397_9ac99f9a48_o.png",
  width = "180px",
  position = css_position(top = "1.5em", right = "1.5em")
)

use_editable(expires = 1)
```

## .phgreenlight[Two Studies, one Result: Student Teachers are Biased by Anchors When Engaging With Evidence]
<br>

.em13[Kirstin Schmidt<sup>1</sup>.white[<sup>†</sup>], Kristina Bohrer<sup>1</sup><sup>†</sup> and Samuel Merk<sup>1</sup>]


<sup>1</sup> Pädagogische Hochschule Karlsruhe <br>
<sup>†</sup> presenting authors <br>
.phgreen[Paper Presenatation EARLI SIG 18 | 09.09.2022]  

---


## .phgreenlight[Structure `r fontawesome::fa_i(name = "list-ul")`]
* Evidence-Informed School Practice <i class="fas fa-school"></i>
* Anchoring Effects 
* Study 1: Anchoring Effects in  Engagement with Data <i class="fas fa-search"></i>
  * Research Question <i class="fas fa-question"></i>
  * Sample `r fontawesome::fa_i(name = "users")`
  * Design and Materials 
  * Results <i class="far fa-chart-bar"></i>
* Study 2: Anchoring Effects in Interpreting Scientific Evidence <i class="fas fa-search"></i>
  * Sample `r fontawesome::fa_i(name = "users")`
  * Design and Materials `r fontawesome::fa_i(name = "align-left")`
  * Results <i class="far fa-chart-bar"></i>
* Discussion <i class="fab fa-weixin"></i>
* References <i class="fas fa-book-open"></i>


---
class: inverse, center, middle

# Evidence-Informed School Practice <i class="fas fa-school"></i>

---
## .phgreenlight[Evidence-Informed School Practice <i class="fas fa-school"></i>]

---
class: inverse, center, middle

# Anchoring Effects 

---
## .phgreenlight[Anchoring Effects]


---
class: inverse, center, middle

# Study 1: Anchoring Effects <br> in Engagement with Data <i class="fas fa-search"></i>

---

## .phgreenlight[Study 1: Anchoring Effects in <br> Engagement with Data <i class="fas fa-search"></i>]

---
class: inverse, center, middle

# Study 2: Anchoring Effects in <br> Interpreting Scientific Evidence <i class="fas fa-search"></i>


???

Research Question <i class="fas fa-question"></i>

---

## .phgreenlight[Sample `r fontawesome::fa_i(name = "users")`]

<center> N = 233 student teachers from the Karlsruhe University of Education </center>

* 85 % female student teachers
* M<sub>semesters</sub> = 3.4
* subjects?


---

## .phgreenlight[Design and Materials `r fontawesome::fa_i(name = "align-left")`]

Randomized Controlled Trial with two within-person factors *topic of educational research* and *sample size*

<img style="vertical-align:middle" src="images/Confhindanch_study_material_1.jpg">

???
- each participant presented with two study reports on different topics from educational research sequentially and in randomized order
- research reports: research question, drawn sample size and experimental design of the study 
- results were presented in a later step, but for the RQ today irrelevant 
- after participants have read the report, decided whether ‘the investigated sample size of students (either N = 15 or N = 500) in the presented study is appropriate to answer the research question’ using a Likert scale ranging from 1 = totally disagree to 7 = totally agree
- two experimental groups: N1 = 15 and N2 = 500 or reverse 
- two control groups: in both research reports the same sample size e.g., N1 = 15 und N2 = 15

---

## .phgreenlight[Design and Materials `r fontawesome::fa_i(name = "align-left")`]

Randomized Controlled Trial with two within-person factors *topic of educational research* and *sample size*

<img style="vertical-align:middle" src="images/Confhindanch_study_material.jpg">

???
- after participants have read the report, decided, among others, whether ‘the investigated sample size of students (either N = 15 or N = 500) in the presented study is appropriate to answer the research question’ using a Likert scale ranging from 1 = totally disagree to 7 = totally agree
- two experimental groups: N1 = 15 and N2 = 500 or reverse 
- two control groups: in both research reports the same sample size e.g., N1 = 15 und N2 = 15

---
## .phgreenlight[Hypothesis]

H<sub>1</sub>: When student teachers are first presented with a small anchor (N<sub>2</sub>=15), they rate the appropriateness of the second large sample size (N<sub>2</sub>=500).

H<sub>2</sub>: When student teachers are first presented with a large anchor (N<sub>2</sub>=500), they rate the second small sample size (N<sub>2</sub>=15) as less appropriate.

H<sub>3</sub>: In the control group, there are no differences between the first and second appropriateness ratings. 


???
wie formuliere ich das am besten als eine Hypothese
---

## .phgreenlight[Results <i class="far fa-chart-bar"></i>]



???

- to analyze whether the sample size presented in the first report acted as an anchor for assessing the adequacy of the sample size in the second report, we subtracted the appropriateness rating of the first study sample from the appropriateness rating of the second one
---
class: inverse, center, middle

# Discussion <i class="fab fa-weixin"></i>

---
## .phgreenlight[Discussion <i class="fab fa-weixin"></i>]

* 
* Both studies indicate evidence for anchoring effects on student teachers' engagement with different types of evidence 

Anchoring effects in data-based decision making....
* ...
* ...

Anchoring effects in interpreting scientific evidence
* Large-scale assessments (e.g., PISA) might act as an anchor resulting in a devaluation of scientific evidence based on smaller sample sizes 
  * sample sizes are not indicator of quality and validity
* mediator ?

* Limitations
---
## .phgreenlight[References <i class="fas fa-book-open"></i>]

.em08[
Akl, E. A., Oxman, A. D., Herrin, J., Vist, G. E., Terrenato, I., Sperati, F., Costiniuk, C., Blank, D., & Schünemann, H. (2011). Using alternative statistical formats for presenting risks and risk reductions. Cochrane Database of Systematic Reviews, 2011(3), Article CD006776. https://doi.org/10.1002/14651858.CD006776.pub2 <br>
Borg, S. (2009). English language teachers’ conceptions of research. Applied Linguistics, 30(3), 358–388. https://doi.org/10.1093/applin/amp007 <br>
Bromme, R., & Goldman, S. R. (2014). The public’s bounded understanding of science. Educational Psychologist, 49(2), 59–69. https://doi.org/10.1080/00461520.2014.921572 <br>
Bromme, R., Kienhues, D., & Porsch, T. (2010). Who knows what and who can we believe? Epistemological beliefs are beliefs about knowledge (mostly) to be attained from others. In L. D. Bendixen & F. C. Feucht (Eds.), Personal epistemology in the classroom (pp. 163–194). Cambridge University Press. https://doi.org/10.1017/CBO9780511691904.006 <br>
Brown, C., Schildkamp, K., & Hubers, M. D. (2017). Combining the best of two worlds: A conceptual proposal for evidence-informed school improvement. Educational Research, 59(2), 154–172. https://doi.org/10.1080/00131881.2017.1304327 <br>
Coe, R. (2002, 12-14 September). It’s the effect size, stupid. What effect size is and why it is important [Paper presentation]. British Educational Research Association annual conference 2002, Exeter, UK. <br>
Cumming, G. (2014). The new statistics: Why and how. Psychological Science, 25(1), 7–29. https://doi.org/10.1177/0956797613504966 <br>
DESTATIS (2021, 17 September). Allgemeinbildende Schulen – Fachserie 11 Reihe 1 – Schuljahr 2020/2021. https://www.statistischebibliothek.de/mir/receive/DEHeft_mods_00136642 <br>
Diery, A., Knogler, M., Mazziotti, C., Schneeweiss, A., Hetmanek, A., Holzberger, D., & Seidel, T. (2020). Das Clearing House Unterricht. Ein Service für die Lehrer*innenbildung?! journal für lehrerInnenbildung, 20(2), 42–51. https://doi.org/10.35468/jlb-02-2020_03 <br>
Gigerenzer, G., & Edwards, A. (2003). Simple tools for understanding risks: From innumeracy to insight. British Medical Journal. https://doi.org/10.1136/bmj.327.7417.741 <br>
Goodman, S. (2008). A dirty dozen: Twelve p-value misconceptions. Seminars in Hematology, 45(3), 135–140. https://doi.org/10.1053/j.seminhematol.2008.04.003 <br>
]

---

## .phgreenlight[Referenzen <i class="fas fa-book-open"></i>]

.em08[
Haller, H., & Krauss, S. (2002). Misinterpretations of significance: A problem students share with their teachers? Methods of Psychological Research, 7(1), 1–20. <br>
Hanel, P. H., & Mehler, D. M. (2019). Beyond reporting statistical significance: Identifying informative effect sizes to improve scientific communication. Public Understanding of Science, 28(4), 468–485. https://doi.org/10.1177/0963662519834193 <br>
Hoijtink, H., Mulder, J., van Lissa, C., & Gu, X. (2019). A tutorial on testing hypotheses using the Bayes factor. Psychological Methods, 24(5), 539–556.https://doi.org/10.1037/met0000201 <br>
Kühberger, A., Fritz, A., Lermer, E., & Scherndl, T. (2015). The significance fallacy in inferential statistics. BMC Research Notes, 8(1), 84. https://doi.org/10.1186/s13104-015-1020-4 <br>
Leat, D., Reid, A., & Lofthouse, R. (2015). Teachers’ experiences of engagement with and in educational research: What can be learned from teachers’ views? Oxford Review of Education, 41(2), 270–286. https://doi.org/10.1080/03054985.2015.1021193 <br>
Lortie-Forgues, H., Sio, U. N., & Inglis, M. (2021). How Should Educational Effects Be Communicated to Teachers? Educational Researcher, 50(6), 345–354. https://doi.org/10.3102/0013189X20987856 <br>
Ostkamp, L. (2017). Understanding the concept of null hypothesis significance testing [Master Thesis, Bielefeld University]. https://osf.io/tc8m4/download <br>
Pierce, R., & Chick, H. (2013). Workplace statistical literacy for teachers: Interpreting box plots. Mathematics Education Research Journal, 25(2), 189–205. https://doi.org/10.1007/s13394-012-0046-3 <br>
Prinz, A., Golke, S., & Wittwer, J. (2019). Refutation texts compensate for detrimental effects of misconceptions on comprehension and metacomprehension accuracy and support transfer. Journal of Educational Psychology, 111(6), 957–981. https://doi.org/10.1037/edu0000329 <br>
Schildkamp, K. (2019). Data-based decision-making for school improvement: Research insights and gaps. Educational Research, 61(3), 257–273. https://doi.org/10.1080/00131881.2019.1625716 <br>
Sotos, A. E. C., Vanhoof, S., Van den Noortgate, W., & Onghena, P. (2009). How confident are students in their misconceptions about hypothesis tests? Journal of Statistics Education, 17(2), 2. https://doi.org/10.1080/10691898.2009.11889514
]
---
class: inverse, center, middle

# Thank you for your attention!
contacts `r fontawesome::fa_i(name = "address-card")`:
.pull-left[
Kirstin Schmidt <br>
Karlsruhe University of Education <br>
Bismarckstraße 10, <br>
76133 Karlsruhe <br>
Germany <br>
.white[kirstin.schmidt@ph-karlsruhe.de] 
] 

.pull-right[
Kristina Bohrer <br>
Karlsruhe University of Education <br>
Bismarckstraße 10, <br>
76133 Karlsruhe <br>
Germany <br>
.white[kristina.bohrer@ph-karlsruhe.de] 
]
